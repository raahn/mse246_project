---
title: "MSE 246 Data Cleaning"
author: "Samuel Hansen"
date: "1/21/2017"
output: 
  html_document:
    toc: true
    keep_md: true 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, 
                      message = FALSE, cache = TRUE, eval = FALSE)
```

#Overview

This script builds predictive models of small-business defaults using 
data spanning 1990-2014 provided by the Small Business Association (SBA). 
To do so, this script implements a pipeline that:

1. Performs feature engineering;
2. Splits the data into train and test sets;
3. Normalizes continuous features;
4. Selects features using recursive feature elimination;
5. Trains binary outcome predictive models, including LASSO and random 
forests. 

Lastly, we evaluate the performance of these models on the held-out test set
in terms of AUC, sensitivity, and calibration. 

```{r}
# Initialize libraries 
library(ggrepel)
library(knitr)
library(lubridate)
library(caret)
library(stringr)
library(plotROC)
library(pROC)
library(tidyverse)

# Initialize input files 
train_file_in <- "../data/train.rds"
test_file_in <- "../data/test.rds"

# Read in data 
train <- read_rds(train_file_in)
test <- read_rds(test_file_in)
```

#Feature Engineering

We engineered the following features from the raw data: 

- `first_zip_digit`: the first digit of the borrower's zip code;
- `NAICS`: the first two digits of the NAICS code;
- `subpgmdesc`: condensed infrequent factor levels into "other" category;
- `approval_year`: extracted year from loan approval datetime object;

#Data Preprocessing

Some variables are on different scales; for example, `Gross Approval` 
varies in dollar amounts from \$30,000  to \$4,000,000, whereas 
`Term in Months` ranges from 1 to 389. In turn, we center and scale the 
predictors to apply regularization techniques during the modeling phase. 
```{r}
# Define pre-processing steps to apply to training data
# preProcessSteps <- c("center", "scale") "pca"? 
preProcessSteps <- c("center", "scale", "nzv", "knnImpute")

# Apply same pre-processing steps to the test set
preProcessObject <- preProcess(train, method = preProcessSteps)
train <- predict(preProcessObject, train)
test <- predict(preProcessObject, test)
```

#Feature Selection

We perform feature selection using recursive feature elimination
with 10-fold cross-validation. This method uses the 
`rfFuncs` parameter, which uses random forests to remove 
variables with low variable importance.
```{r, eval=FALSE}
# Set the recursive feature elimination parameters 
set.seed(1234)
rfFuncs$summary <- twoClassSummary
rfe.cntrl <- rfeControl(functions = rfFuncs,
                      method = "cv",
                      number = 5,
                      returnResamp = "final")
train.cntrl <- trainControl(selectionFunction = "oneSE",
                            classProbs = TRUE,
                            summaryFunction = twoClassSummary)

# Perform recursive feature elimination to select variables
rfe.results <-
  rfe(LoanStatus~.,
      data = train,
      rfeControl = rfe.cntrl,
      preProc = preProcessSteps,
      metric = "ROC",
      trControl = train.cntrl)
```

```{r, echo = FALSE}
rfe.results <- read_rds("../models/rfe.results.rds")
```


The following table shows that recursive feature selection 
chooses `r rfe.results[["results"]]$Variables[which.max(rfe.results[["results"]]$ROC)]`
variables to include in subsequent model building.
```{r}
print(rfe.results)
```

The procedure selects `r rfe.results[["results"]]$Variables[which.max(rfe.results[["results"]]$ROC)]` 
variables because AUC is maximized (see plot below):
```{r}
ggplot(rfe.results) +
  labs(x = "Number of Variables",
       y = "AUC (Cross-Validated)",
       title = "Recursive Feature Elimination\nNumber of Variables vs. AUC")
```

The importances of the top 30 selected features are given by:
```{r, fig.height=8, fig.width=7}
data_frame(predictor = rownames(varImp(rfe.results)), 
           var_imp = varImp(rfe.results)$Overall) %>%
  slice(1:30) %>%
  ggplot(mapping = aes(x = reorder(predictor, var_imp), y = var_imp)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(x = "", 
       y = "Variable Importance", 
       title = "Recursive Feature Elimination Variable Importance")
```

```{r}
# Map factor levels back to their respective features 
(selected_vars <- map(predictors(rfe.results), ~str_match(.x, names(df))) %>% 
  unlist() %>% 
  .[!is.na(.)] %>%
  unique())
train_selected_vars <- train %>%
  select(one_of(selected_vars), LoanStatus)
```

```{r, echo = FALSE}
train_selected_vars <-
  train_selected_vars %>%
  mutate(LoanStatus = if_else(LoanStatus == 1, "default", "paid")) %>%
  dmap_at("LoanStatus", factor)
```

#Model Fitting 

Using these selected features, we fit models predicting the binary outcome
of whether a small busniess defaults on a loan. To tune hyperparameters,
we use 10-fold cross-validation with the one standard-error rule, which selects
parameters that obtain the highest cross-validated AUC within one standard error
of the maximum. 

```{r}
# Define cross-validation controls 
cvCtrl <- trainControl(method = "cv", 
                       number = 10,
                       summaryFunction = twoClassSummary, 
                       selectionFunction = "oneSE",
                       classProbs = TRUE)
```

##Elastic Net

We fit an elastic net model as follows:
```{r, eval=FALSE}
# Fit penalized logistic regression model (elastic net)
elastic.fit <- train(LoanStatus ~ .,
                   data = train_selected_vars,
                   preProc = preProcessSteps,
                   method = "glmnet",
                   family = "binomial",
                   trControl = cvCtrl,
                   metric = "ROC")
```

The elastic net model was selected with the following hyperparameters:
```{r, echo = FALSE, fig.width=6, fig.height=6}
elastic.fit <- read_rds("../models/elastic.fit.rds")
elastic.fit
plot(elastic.fit)
```

##Random Forest

We fit a random forest model as follows:
```{r, eval=FALSE}
# Fit penalized logistic regression model (elastic net)
rf.fit <- train(LoanStatus ~ .,
                   data = train_selected_vars,
                   preProc = preProcessSteps,
                   method = "rf",
                   trControl = cvCtrl,
                   metric = "ROC")
```

The random forestmodel was selected with the following hyperparameters:
```{r, echo = FALSE, fig.width=6, fig.height=6}
rf.fit <- read_rds("../models/rf.fit.rds")
rf.fit
plot(rf.fit)
```

#Model Evaluation 

##ROC Plots 

```{r}
# Evaluate performance of trained models on test set 
testResults <- data.frame(true_value = test$LoanStatus)
testResults$randomForest <- predict(rf.fit, test, type = "prob")[,"default"]
testResults$elasticNet <- predict(elastic.fit, test, type = "prob")[,"default"]

# Compute AUC by model type 
aucs <-
  data_frame(randomForest = pROC::auc(roc(predictor = testResults$randomForest,
                       response = testResults$true_value)),
             elasticNet = pROC::auc(roc(predictor = testResults$elasticNet,
                       response = testResults$true_value))) %>%
  gather(method, auc_value, randomForest:elasticNet) %>%
  mutate(auc_label = paste("AUC =", round(auc_value,3)))

# Gather results in long format 
testResults <- 
  testResults %>%
  gather(method, predicted_prob, randomForest:elasticNet) %>%
  mutate(true_value = ifelse(true_value == "default", 1, 0))
```

```{r, fig.width=9, fig.height=6}
model_labels <- c("randomForest" = "Random Forest",
                  "elasticNet" = "Elastic Net")

# Plot ROC curves by model type 
testResults %>%
  ggplot(mapping = aes(d = true_value, m = predicted_prob)) +
  geom_roc(n.cuts = 5, labelsize = 2, labelround = 3) +
  annotate(geom = "segment", x = 0, xend = 1, y = 0, yend = 1,
           color = "black", linetype = 2) +
  labs(x = "False Positive Fraction", y = "True Positive Fraction",
       title = "ROC Curves by Model Type") +
  facet_wrap(~method, labeller = labeller(method = model_labels)) +
  geom_text(data = aucs, aes(x = 0.75, y = 0.5, label = auc_label), 
                    colour = "black", inherit.aes = FALSE, parse = FALSE)
```

##Calibration Plots 

```{r, fig.width=9, fig.height=6}
# Make calibration plots, facetted by model type
pred_prob_midpoints <- data_frame(midpoint = rep(seq(0.025, 0.975, 0.05), each = 2))
testResults %>%
  mutate(prob_bin = cut_width(predicted_prob,width = 0.05)) %>%
  group_by(prob_bin, method) %>%
  summarise(prob_default = mean(true_value, na.rm = TRUE),
            n = n()) %>%
  bind_cols(., pred_prob_midpoints) %>%
  ungroup() %>%
  ggplot(mapping = aes(x = midpoint, y = prob_default, label = n)) +
  geom_line() +
  geom_point(mapping = aes(size = n)) +
  geom_text_repel(mapping = aes(color = "red")) +
  annotate(geom = "segment", x = 0, xend = 1, y = 0, yend = 1,
           color = "black", linetype = 2) +
  scale_x_continuous(labels = scales::percent,
                     breaks = seq(0, 1, by = 0.1)) +
  scale_y_continuous(labels = scales::percent,
                     breaks = seq(0, 1, by = 0.1)) +
  scale_colour_discrete(guide = FALSE) +
  scale_size(name = "Number of\nPredictions",
             labels = scales::comma) +
  labs(x = "Predicted Default Probability (Bin Midpoint)",
       y = "Actual Default Probability",
       title = "Calibration Plot: Predicted vs. Actual Default Probability") +
  facet_wrap(~method, labeller = labeller(method = model_labels))
```

```{r, echo = FALSE}
#IGNORE THIS CODE FOR NOW

# # Selection by Filter
# # Set the selection by filter parameters 
# set.seed(1234)
# rfFuncs$summary <- twoClassSummary
# sbf.cntrl <- sbfControl(functions = rfSBF,
#                       method = "cv",
#                       number = 5,
#                       returnResamp = "final")
# train.cntrl <- trainControl(selectionFunction = "oneSE",
#                             classProbs = TRUE,
#                             summaryFunction = twoClassSummary)
# 
# # Perform selection by filter to select variables 
# sbf.results <- 
#   sbf(LoanStatus~., 
#       data = train,
#       sbfControl = sbf.cntrl, 
#       preProc = preProcessSteps,
#       metric = "ROC",
#       trControl = train.cntrl)
```

